{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query_ChatGPT import query_ChatGPT\n",
    "from query_Claude import query_all_claude\n",
    "from query_LLM import send_query\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>GPT4o_CoT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what do these '1/2 naked pics' have to do with...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That's coming, but I think the victims are goi...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow,first Hugo Chavez and now Fidel Castro. Da...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Fake news, Election Day hacks, Wikileaks, Come...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>I just want to move to LA, work a minimum wage...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>I dunno, from my porch view of Europe, there i...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Watch Tesla Model S P85D’s instant speed avoid...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Positive news - #France to enforce labeling of...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  GPT4o_CoT\n",
       "0    what do these '1/2 naked pics' have to do with...      5          2\n",
       "1    OH: “I had a blue penis while I was this” [pla...      5          3\n",
       "2    That's coming, but I think the victims are goi...      5          2\n",
       "3    I think I may be finally in with the in crowd ...     10          8\n",
       "4    Wow,first Hugo Chavez and now Fidel Castro. Da...      0          3\n",
       "..                                                 ...    ...        ...\n",
       "245  Fake news, Election Day hacks, Wikileaks, Come...      0          2\n",
       "246  I just want to move to LA, work a minimum wage...      5          8\n",
       "247  I dunno, from my porch view of Europe, there i...      0          2\n",
       "248  Watch Tesla Model S P85D’s instant speed avoid...     10          8\n",
       "249  Positive news - #France to enforce labeling of...     10          7\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = pd.read_csv(\"temp.csv\")\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = test_text['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  Qwen 1.5 Chat (0.5B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:25<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  Qwen 1.5 Chat (1.8B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [04:43<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  Qwen 1.5 Chat (4B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:15<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  Qwen 1.5 Chat (7B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:31<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  Qwen 1.5 Chat (14B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [04:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  Qwen 1.5 Chat (72B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [10:06<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  LLaMA-2 Chat (70B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [10:21<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  GPT-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'message': ['model must be one of the following values: zero-one-ai/Yi-34B-Chat, allenai/OLMo-7B-Instruct, allenai/OLMo-7B-Twin-2T, allenai/OLMo-7B, Austism/chronos-hermes-13b, cognitivecomputations/dolphin-2.5-mixtral-8x7b, deepseek-ai/deepseek-coder-33b-instruct, deepseek-ai/deepseek-llm-67b-chat, garage-bAInd/Platypus2-70B-instruct, google/gemma-2b-it, google/gemma-7b-it, Gryphe/MythoMax-L2-13b, lmsys/vicuna-13b-v1.5, lmsys/vicuna-7b-v1.5, codellama/CodeLlama-13b-Instruct-hf, codellama/CodeLlama-34b-Instruct-hf, codellama/CodeLlama-70b-Instruct-hf, codellama/CodeLlama-7b-Instruct-hf, meta-llama/Llama-2-70b-chat-hf, meta-llama/Llama-2-13b-chat-hf, meta-llama/Llama-2-7b-chat-hf, mistralai/Mistral-7B-Instruct-v0.1, mistralai/Mistral-7B-Instruct-v0.2, mistralai/Mixtral-8x7B-Instruct-v0.1, mistralai/Mistral-7B-Instruct-v0.3, NousResearch/Nous-Capybara-7B-V1p9, NousResearch/Nous-Hermes-2-Mistral-7B-DPO, NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO, NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT, NousResearch/Nous-Hermes-llama-2-7b, NousResearch/Nous-Hermes-Llama2-13b, NousResearch/Nous-Hermes-2-Yi-34B, openchat/openchat-3.5-1210, Open-Orca/Mistral-7B-OpenOrca, Qwen/Qwen1.5-0.5B-Chat, Qwen/Qwen1.5-1.8B-Chat, Qwen/Qwen1.5-4B-Chat, Qwen/Qwen1.5-7B-Chat, Qwen/Qwen1.5-14B-Chat, Qwen/Qwen1.5-72B-Chat, snorkelai/Snorkel-Mistral-PairRM-DPO, togethercomputer/alpaca-7b, teknium/OpenHermes-2-Mistral-7B, teknium/OpenHermes-2p5-Mistral-7B, togethercomputer/Llama-2-7B-32K-Instruct, togethercomputer/RedPajama-INCITE-Chat-3B-v1, togethercomputer/RedPajama-INCITE-7B-Chat, togethercomputer/StripedHyena-Nous-7B, Undi95/ReMM-SLERP-L2-13B, Undi95/Toppy-M-7B, WizardLM/WizardLM-13B-V1.2, upstage/SOLAR-10.7B-Instruct-v1.0, zero-one-ai/Yi-34B, zero-one-ai/Yi-6B, google/gemma-2b, google/gemma-7b, meta-llama/Llama-2-70b-hf, meta-llama/Llama-2-13b-hf, meta-llama/Llama-2-7b-hf, microsoft/phi-2, Nexusflow/NexusRaven-V2-13B, Qwen/Qwen1.5-0.5B, Qwen/Qwen1.5-1.8B, Qwen/Qwen1.5-4B, Qwen/Qwen1.5-7B, Qwen/Qwen1.5-14B, Qwen/Qwen1.5-72B, togethercomputer/GPT-JT-Moderation-6B, togethercomputer/LLaMA-2-7B-32K, togethercomputer/RedPajama-INCITE-Base-3B-v1, togethercomputer/RedPajama-INCITE-7B-Base, togethercomputer/RedPajama-INCITE-Instruct-3B-v1, togethercomputer/RedPajama-INCITE-7B-Instruct, togethercomputer/StripedHyena-Hessian-7B, mistralai/Mistral-7B-v0.1, mistralai/Mixtral-8x7B-v0.1, codellama/CodeLlama-70b-Python-hf, codellama/CodeLlama-34b-Python-hf, codellama/CodeLlama-13b-Python-hf, codellama/CodeLlama-7b-Python-hf, Phind/Phind-CodeLlama-34B-v2, WizardLM/WizardCoder-Python-34B-V1.0, Meta-Llama/Llama-Guard-7b, togethercomputer/evo-1-8k-base, togethercomputer/evo-1-131k-base, databricks/dolly-v2-12b, databricks/dolly-v2-3b, databricks/dolly-v2-7b, DiscoResearch/DiscoLM-mixtral-8x7b-v2, HuggingFaceH4/zephyr-7b-beta, HuggingFaceH4/starchat-alpha, OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5, OpenAssistant/stablelm-7b-sft-v7-epoch-3, togethercomputer/Koala-13B, togethercomputer/Koala-7B, lmsys/vicuna-13b-v1.3, lmsys/vicuna-7b-v1.3, lmsys/fastchat-t5-3b-v1.0, togethercomputer/mpt-30b-chat, togethercomputer/mpt-7b-chat, NousResearch/Nous-Hermes-Llama2-70b, Qwen/Qwen-7B-Chat, Qwen/Qwen-14B-Chat, tiiuae/falcon-7b-instruct, tiiuae/falcon-40b-instruct, togethercomputer/guanaco-13b, togethercomputer/guanaco-33b, togethercomputer/guanaco-65b, togethercomputer/guanaco-7b, togethercomputer/GPT-NeoXT-Chat-Base-20B, togethercomputer/Pythia-Chat-Base-7B-v0.16, defog/sqlcoder, EleutherAI/gpt-j-6b, EleutherAI/gpt-neox-20b, EleutherAI/llemma_7b, EleutherAI/pythia-12b-v0, EleutherAI/pythia-1b-v0, EleutherAI/pythia-2.8b-v0, EleutherAI/pythia-6.9b, google/flan-t5-xl, google/flan-t5-xxl, huggyllama/llama-7b, huggyllama/llama-13b, huggyllama/llama-30b, huggyllama/llama-65b, mosaicml/mpt-7b, mosaicml/mpt-7b-instruct, NousResearch/Nous-Hermes-13b, NumbersStation/nsql-6B, Qwen/Qwen-7B, Qwen/Qwen-14B, stabilityai/stablelm-base-alpha-3b, stabilityai/stablelm-base-alpha-7b, tiiuae/falcon-7b, tiiuae/falcon-40b, togethercomputer/GPT-JT-6B-v1, WizardLM/WizardLM-70B-V1.0, bigcode/starcoder, codellama/CodeLlama-70b-hf, NumbersStation/nsql-llama-2-7B, Phind/Phind-CodeLlama-34B-Python-v1, replit/replit-code-v1-3b, Salesforce/codegen2-16B, Salesforce/codegen2-7B, meta-llama/Llama-3-8b-chat-hf, meta-llama/Llama-3-70b-chat-hf, meta-llama/Llama-3-8b-hf, meta-llama/Meta-Llama-3-70B, meta-llama/LlamaGuard-2-8b, databricks/dbrx-instruct, mistralai/Mixtral-8x22B-Instruct-v0.1, mistralai/Mixtral-8x22B, gpt-4, gpt-4-turbo, gpt-4-0613, gpt-4-32k, gpt-4-32k-0613, gpt-3.5-turbo-0125, gpt-3.5-turbo, gpt-3.5-turbo-1106, gpt-3.5-turbo-instruct, gpt-3.5-turbo-16k, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, gpt-4o, claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307'], 'error': 'Bad Request', 'statusCode': 400}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m responses[k] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(all_text):\n\u001b[1;32m----> 7\u001b[0m     responses[k]\u001b[38;5;241m.\u001b[39mappend(\u001b[43msend_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCoT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Zihan liu\\Documents\\GitHub\\MATH189_final_project\\LLM_quries\\query_LLM.py:16\u001b[0m, in \u001b[0;36msend_query\u001b[1;34m(model, input_sentence, CoT)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_query\u001b[39m(model, input_sentence, CoT\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m CoT:\n\u001b[1;32m---> 16\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPrompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCoT_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sentence\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mPlease provide sentiment analysis of this sentence as instructed:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m         response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     29\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     30\u001b[0m             messages\u001b[38;5;241m=\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m             max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[0;32m     38\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Zihan liu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zihan liu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\resources\\chat\\completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zihan liu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1239\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Zihan liu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zihan liu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\openai\\_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1028\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'message': ['model must be one of the following values: zero-one-ai/Yi-34B-Chat, allenai/OLMo-7B-Instruct, allenai/OLMo-7B-Twin-2T, allenai/OLMo-7B, Austism/chronos-hermes-13b, cognitivecomputations/dolphin-2.5-mixtral-8x7b, deepseek-ai/deepseek-coder-33b-instruct, deepseek-ai/deepseek-llm-67b-chat, garage-bAInd/Platypus2-70B-instruct, google/gemma-2b-it, google/gemma-7b-it, Gryphe/MythoMax-L2-13b, lmsys/vicuna-13b-v1.5, lmsys/vicuna-7b-v1.5, codellama/CodeLlama-13b-Instruct-hf, codellama/CodeLlama-34b-Instruct-hf, codellama/CodeLlama-70b-Instruct-hf, codellama/CodeLlama-7b-Instruct-hf, meta-llama/Llama-2-70b-chat-hf, meta-llama/Llama-2-13b-chat-hf, meta-llama/Llama-2-7b-chat-hf, mistralai/Mistral-7B-Instruct-v0.1, mistralai/Mistral-7B-Instruct-v0.2, mistralai/Mixtral-8x7B-Instruct-v0.1, mistralai/Mistral-7B-Instruct-v0.3, NousResearch/Nous-Capybara-7B-V1p9, NousResearch/Nous-Hermes-2-Mistral-7B-DPO, NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO, NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT, NousResearch/Nous-Hermes-llama-2-7b, NousResearch/Nous-Hermes-Llama2-13b, NousResearch/Nous-Hermes-2-Yi-34B, openchat/openchat-3.5-1210, Open-Orca/Mistral-7B-OpenOrca, Qwen/Qwen1.5-0.5B-Chat, Qwen/Qwen1.5-1.8B-Chat, Qwen/Qwen1.5-4B-Chat, Qwen/Qwen1.5-7B-Chat, Qwen/Qwen1.5-14B-Chat, Qwen/Qwen1.5-72B-Chat, snorkelai/Snorkel-Mistral-PairRM-DPO, togethercomputer/alpaca-7b, teknium/OpenHermes-2-Mistral-7B, teknium/OpenHermes-2p5-Mistral-7B, togethercomputer/Llama-2-7B-32K-Instruct, togethercomputer/RedPajama-INCITE-Chat-3B-v1, togethercomputer/RedPajama-INCITE-7B-Chat, togethercomputer/StripedHyena-Nous-7B, Undi95/ReMM-SLERP-L2-13B, Undi95/Toppy-M-7B, WizardLM/WizardLM-13B-V1.2, upstage/SOLAR-10.7B-Instruct-v1.0, zero-one-ai/Yi-34B, zero-one-ai/Yi-6B, google/gemma-2b, google/gemma-7b, meta-llama/Llama-2-70b-hf, meta-llama/Llama-2-13b-hf, meta-llama/Llama-2-7b-hf, microsoft/phi-2, Nexusflow/NexusRaven-V2-13B, Qwen/Qwen1.5-0.5B, Qwen/Qwen1.5-1.8B, Qwen/Qwen1.5-4B, Qwen/Qwen1.5-7B, Qwen/Qwen1.5-14B, Qwen/Qwen1.5-72B, togethercomputer/GPT-JT-Moderation-6B, togethercomputer/LLaMA-2-7B-32K, togethercomputer/RedPajama-INCITE-Base-3B-v1, togethercomputer/RedPajama-INCITE-7B-Base, togethercomputer/RedPajama-INCITE-Instruct-3B-v1, togethercomputer/RedPajama-INCITE-7B-Instruct, togethercomputer/StripedHyena-Hessian-7B, mistralai/Mistral-7B-v0.1, mistralai/Mixtral-8x7B-v0.1, codellama/CodeLlama-70b-Python-hf, codellama/CodeLlama-34b-Python-hf, codellama/CodeLlama-13b-Python-hf, codellama/CodeLlama-7b-Python-hf, Phind/Phind-CodeLlama-34B-v2, WizardLM/WizardCoder-Python-34B-V1.0, Meta-Llama/Llama-Guard-7b, togethercomputer/evo-1-8k-base, togethercomputer/evo-1-131k-base, databricks/dolly-v2-12b, databricks/dolly-v2-3b, databricks/dolly-v2-7b, DiscoResearch/DiscoLM-mixtral-8x7b-v2, HuggingFaceH4/zephyr-7b-beta, HuggingFaceH4/starchat-alpha, OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5, OpenAssistant/stablelm-7b-sft-v7-epoch-3, togethercomputer/Koala-13B, togethercomputer/Koala-7B, lmsys/vicuna-13b-v1.3, lmsys/vicuna-7b-v1.3, lmsys/fastchat-t5-3b-v1.0, togethercomputer/mpt-30b-chat, togethercomputer/mpt-7b-chat, NousResearch/Nous-Hermes-Llama2-70b, Qwen/Qwen-7B-Chat, Qwen/Qwen-14B-Chat, tiiuae/falcon-7b-instruct, tiiuae/falcon-40b-instruct, togethercomputer/guanaco-13b, togethercomputer/guanaco-33b, togethercomputer/guanaco-65b, togethercomputer/guanaco-7b, togethercomputer/GPT-NeoXT-Chat-Base-20B, togethercomputer/Pythia-Chat-Base-7B-v0.16, defog/sqlcoder, EleutherAI/gpt-j-6b, EleutherAI/gpt-neox-20b, EleutherAI/llemma_7b, EleutherAI/pythia-12b-v0, EleutherAI/pythia-1b-v0, EleutherAI/pythia-2.8b-v0, EleutherAI/pythia-6.9b, google/flan-t5-xl, google/flan-t5-xxl, huggyllama/llama-7b, huggyllama/llama-13b, huggyllama/llama-30b, huggyllama/llama-65b, mosaicml/mpt-7b, mosaicml/mpt-7b-instruct, NousResearch/Nous-Hermes-13b, NumbersStation/nsql-6B, Qwen/Qwen-7B, Qwen/Qwen-14B, stabilityai/stablelm-base-alpha-3b, stabilityai/stablelm-base-alpha-7b, tiiuae/falcon-7b, tiiuae/falcon-40b, togethercomputer/GPT-JT-6B-v1, WizardLM/WizardLM-70B-V1.0, bigcode/starcoder, codellama/CodeLlama-70b-hf, NumbersStation/nsql-llama-2-7B, Phind/Phind-CodeLlama-34B-Python-v1, replit/replit-code-v1-3b, Salesforce/codegen2-16B, Salesforce/codegen2-7B, meta-llama/Llama-3-8b-chat-hf, meta-llama/Llama-3-70b-chat-hf, meta-llama/Llama-3-8b-hf, meta-llama/Meta-Llama-3-70B, meta-llama/LlamaGuard-2-8b, databricks/dbrx-instruct, mistralai/Mixtral-8x22B-Instruct-v0.1, mistralai/Mixtral-8x22B, gpt-4, gpt-4-turbo, gpt-4-0613, gpt-4-32k, gpt-4-32k-0613, gpt-3.5-turbo-0125, gpt-3.5-turbo, gpt-3.5-turbo-1106, gpt-3.5-turbo-instruct, gpt-3.5-turbo-16k, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, gpt-4o, claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307'], 'error': 'Bad Request', 'statusCode': 400}"
     ]
    }
   ],
   "source": [
    "responses = {}\n",
    "model_names = {'Qwen 1.5 Chat (0.5B)': 'Qwen/Qwen1.5-0.5B-Chat', 'Qwen 1.5 Chat (1.8B)': 'Qwen/Qwen1.5-1.8B-Chat', 'Qwen 1.5 Chat (4B)': 'Qwen/Qwen1.5-4B-Chat', 'Qwen 1.5 Chat (7B)': 'Qwen/Qwen1.5-7B-Chat', 'Qwen 1.5 Chat (14B)': 'Qwen/Qwen1.5-14B-Chat', 'Qwen 1.5 Chat (72B)': 'Qwen/Qwen1.5-72B-Chat', 'LLaMA-2 Chat (70B)': 'meta-llama/Llama-2-70b-chat-hf', 'GPT-4o' : 'gpt-4o', 'GPT-3.5 Turbo': 'gpt-3.5-turbo', 'GPT-4 Turbo': 'gpt-4-turbo'}\n",
    "for k,v in model_names.items():\n",
    "    print('Testing model: ', k)\n",
    "    responses[k] = []\n",
    "    for text in tqdm(all_text):\n",
    "        responses[k].append(send_query(v, text, CoT=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  GPT-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [06:52<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  GPT-3.5 Turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [05:27<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:  GPT-4 Turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [14:50<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "responses_gpt = {}\n",
    "model_names = {'GPT-4o' : 'gpt-4o', 'GPT-3.5 Turbo': 'gpt-3.5-turbo', 'GPT-4 Turbo': 'gpt-4-turbo'}\n",
    "for k,v in model_names.items():\n",
    "    print('Testing model: ', k)\n",
    "    responses_gpt[k] = []\n",
    "    for text in tqdm(all_text):\n",
    "        responses_gpt[k].append(send_query(v, text, CoT=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('responses.json', 'w') as f:\n",
    "    json.dump(responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 'The sentiment of the sentence appears to be negative. The speaker seems frustrated or confused about the relevance or appropriateness of the \"1/2 naked pics.\" Words like \"what do these\" and \"they\\'re not even like that\" suggest disapproval or criticism. The tone indicates a challenging or dismissive attitude towards the subject matter.\\n\\nRating: 2')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_query('gpt-4o', all_text[0], CoT=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When Ryan privatizes SS, Medicare, Medicaid, & does away with ACA, what will Trump\\'s base feel about \"change\" then? That\\'s a big one right?!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_only = {}\n",
    "for k,v in responses.items():\n",
    "    if k != 'GPT-4o':\n",
    "        rating_only[k] = []\n",
    "        for r in v:\n",
    "            rating_only[k].append(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_llama = pd.DataFrame(rating_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen 1.5 Chat (0.5B)    156\n",
       "Qwen 1.5 Chat (1.8B)     25\n",
       "Qwen 1.5 Chat (4B)       75\n",
       "Qwen 1.5 Chat (7B)        0\n",
       "Qwen 1.5 Chat (14B)       1\n",
       "Qwen 1.5 Chat (72B)       0\n",
       "LLaMA-2 Chat (70B)        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_llama.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qwen 1.5 Chat (0.5B)</th>\n",
       "      <th>Qwen 1.5 Chat (1.8B)</th>\n",
       "      <th>Qwen 1.5 Chat (4B)</th>\n",
       "      <th>Qwen 1.5 Chat (7B)</th>\n",
       "      <th>Qwen 1.5 Chat (14B)</th>\n",
       "      <th>Qwen 1.5 Chat (72B)</th>\n",
       "      <th>LLaMA-2 Chat (70B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Qwen 1.5 Chat (0.5B)  Qwen 1.5 Chat (1.8B)  Qwen 1.5 Chat (4B)  \\\n",
       "0                     1.0                   3.0                 1.0   \n",
       "1                     7.0                   7.0                 0.0   \n",
       "2                     7.0                   5.0                 2.0   \n",
       "3                     NaN                   7.0                 NaN   \n",
       "4                     7.0                   7.0                 2.0   \n",
       "..                    ...                   ...                 ...   \n",
       "245                   NaN                   5.0                 6.0   \n",
       "246                   7.0                   7.0                 NaN   \n",
       "247                   NaN                   1.0                 6.0   \n",
       "248                   9.0                  10.0                 0.0   \n",
       "249                   NaN                   7.0                10.0   \n",
       "\n",
       "     Qwen 1.5 Chat (7B)  Qwen 1.5 Chat (14B)  Qwen 1.5 Chat (72B)  \\\n",
       "0                     6                  3.0                    3   \n",
       "1                     0                  3.0                    3   \n",
       "2                     5                  3.0                    4   \n",
       "3                     8                  6.0                    6   \n",
       "4                     2                  3.0                    4   \n",
       "..                  ...                  ...                  ...   \n",
       "245                   1                  3.0                    5   \n",
       "246                   7                  6.0                    8   \n",
       "247                   6                  4.0                    5   \n",
       "248                   9                  7.0                    5   \n",
       "249                   9                  6.0                    8   \n",
       "\n",
       "     LLaMA-2 Chat (70B)  \n",
       "0                   3.0  \n",
       "1                   6.0  \n",
       "2                   3.0  \n",
       "3                   8.0  \n",
       "4                   3.0  \n",
       "..                  ...  \n",
       "245                 3.0  \n",
       "246                 8.0  \n",
       "247                 3.0  \n",
       "248                 8.0  \n",
       "249                 8.0  \n",
       "\n",
       "[250 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPT-4o</th>\n",
       "      <th>GPT-3.5 Turbo</th>\n",
       "      <th>GPT-4 Turbo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPT-4o  GPT-3.5 Turbo  GPT-4 Turbo\n",
       "0         3              3            5\n",
       "1         5              5            6\n",
       "2         2              2            3\n",
       "3         8              8            8\n",
       "4         3              2            2\n",
       "..      ...            ...          ...\n",
       "245       3              2            4\n",
       "246       8              8            8\n",
       "247       3              3            3\n",
       "248       8              9            8\n",
       "249       6              6            8\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_only_gpt = {}\n",
    "for k,v in responses_gpt.items():\n",
    "    rating_only_gpt[k] = []\n",
    "    for r in v:\n",
    "        rating_only_gpt[k].append(r[0])\n",
    "gpt_CoT = pd.DataFrame(rating_only_gpt)\n",
    "gpt_CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qwen 1.5 Chat (0.5B)</th>\n",
       "      <th>Qwen 1.5 Chat (1.8B)</th>\n",
       "      <th>Qwen 1.5 Chat (4B)</th>\n",
       "      <th>Qwen 1.5 Chat (7B)</th>\n",
       "      <th>Qwen 1.5 Chat (14B)</th>\n",
       "      <th>Qwen 1.5 Chat (72B)</th>\n",
       "      <th>LLaMA-2 Chat (70B)</th>\n",
       "      <th>GPT-4o</th>\n",
       "      <th>GPT-3.5 Turbo</th>\n",
       "      <th>GPT-4 Turbo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Qwen 1.5 Chat (0.5B)  Qwen 1.5 Chat (1.8B)  Qwen 1.5 Chat (4B)  \\\n",
       "0                     1.0                   3.0                 1.0   \n",
       "1                     7.0                   7.0                 0.0   \n",
       "2                     7.0                   5.0                 2.0   \n",
       "3                     NaN                   7.0                 NaN   \n",
       "4                     7.0                   7.0                 2.0   \n",
       "..                    ...                   ...                 ...   \n",
       "245                   NaN                   5.0                 6.0   \n",
       "246                   7.0                   7.0                 NaN   \n",
       "247                   NaN                   1.0                 6.0   \n",
       "248                   9.0                  10.0                 0.0   \n",
       "249                   NaN                   7.0                10.0   \n",
       "\n",
       "     Qwen 1.5 Chat (7B)  Qwen 1.5 Chat (14B)  Qwen 1.5 Chat (72B)  \\\n",
       "0                     6                  3.0                    3   \n",
       "1                     0                  3.0                    3   \n",
       "2                     5                  3.0                    4   \n",
       "3                     8                  6.0                    6   \n",
       "4                     2                  3.0                    4   \n",
       "..                  ...                  ...                  ...   \n",
       "245                   1                  3.0                    5   \n",
       "246                   7                  6.0                    8   \n",
       "247                   6                  4.0                    5   \n",
       "248                   9                  7.0                    5   \n",
       "249                   9                  6.0                    8   \n",
       "\n",
       "     LLaMA-2 Chat (70B)  GPT-4o  GPT-3.5 Turbo  GPT-4 Turbo  \n",
       "0                   3.0       3              3            5  \n",
       "1                   6.0       5              5            6  \n",
       "2                   3.0       2              2            3  \n",
       "3                   8.0       8              8            8  \n",
       "4                   3.0       3              2            2  \n",
       "..                  ...     ...            ...          ...  \n",
       "245                 3.0       3              2            4  \n",
       "246                 8.0       8              8            8  \n",
       "247                 3.0       3              3            3  \n",
       "248                 8.0       8              9            8  \n",
       "249                 8.0       6              6            8  \n",
       "\n",
       "[250 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_CoT = pd.concat([qwen_llama, gpt_CoT], axis=1)\n",
    "all_CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:57<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "gpt_4o_wo_CoT = []\n",
    "for text in tqdm(all_text):\n",
    "    gpt_4o_wo_CoT.append(send_query('gpt-4o', text, CoT=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_CoT['GPT-4o W/O Reasoning'] = [x[0] for x in gpt_4o_wo_CoT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_CoT.to_csv('no_interpolation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2024)\n",
    "def interpolate_missing_values(df):\n",
    "    for column in df.columns:\n",
    "        empirical_distribution = df[column].dropna().values\n",
    "        df[column] = df[column].apply(lambda x: np.random.choice(empirical_distribution) if pd.isna(x) else x)\n",
    "    return df\n",
    "interpolated = interpolate_missing_values(all_CoT).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated = pd.concat([test_text, interpolated], axis=1).drop('GPT4o_CoT', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_responses = pd.read_csv('human_responses.csv')\n",
    "pd.merge(human_responses, interpolated, on='text').to_csv('all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
