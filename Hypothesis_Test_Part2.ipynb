{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb1bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca92cd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Label_by_zihan</th>\n",
       "      <th>Label_by_ben</th>\n",
       "      <th>Label_by_nicole</th>\n",
       "      <th>average</th>\n",
       "      <th>Qwen 1.5 Chat (0.5B)</th>\n",
       "      <th>Qwen 1.5 Chat (1.8B)</th>\n",
       "      <th>Qwen 1.5 Chat (4B)</th>\n",
       "      <th>Qwen 1.5 Chat (7B)</th>\n",
       "      <th>Qwen 1.5 Chat (14B)</th>\n",
       "      <th>Qwen 1.5 Chat (72B)</th>\n",
       "      <th>LLaMA-2 Chat (70B)</th>\n",
       "      <th>GPT-4o</th>\n",
       "      <th>GPT-3.5 Turbo</th>\n",
       "      <th>GPT-4 Turbo</th>\n",
       "      <th>GPT-4o W/O Reasoning</th>\n",
       "      <th>Sentiment Roberta</th>\n",
       "      <th>Custmized Bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what do these '1/2 naked pics' have to do with...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000812</td>\n",
       "      <td>3.385936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.122762</td>\n",
       "      <td>6.015794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That's coming, but I think the victims are goi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.173433</td>\n",
       "      <td>4.166149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.907494</td>\n",
       "      <td>7.103713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow,first Hugo Chavez and now Fidel Castro. Da...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.960894</td>\n",
       "      <td>3.268210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Label_by_zihan  \\\n",
       "0  what do these '1/2 naked pics' have to do with...             3.0   \n",
       "1  OH: “I had a blue penis while I was this” [pla...             5.0   \n",
       "2  That's coming, but I think the victims are goi...             5.0   \n",
       "3  I think I may be finally in with the in crowd ...             7.0   \n",
       "4  Wow,first Hugo Chavez and now Fidel Castro. Da...             4.0   \n",
       "\n",
       "   Label_by_ben  Label_by_nicole   average  Qwen 1.5 Chat (0.5B)  \\\n",
       "0           3.0              4.0  3.333333                   1.0   \n",
       "1           5.0              6.0  5.333333                   7.0   \n",
       "2           6.0              5.0  5.333333                   7.0   \n",
       "3           9.0              7.0  7.666667                   7.0   \n",
       "4           2.0              3.0  3.000000                   7.0   \n",
       "\n",
       "   Qwen 1.5 Chat (1.8B)  Qwen 1.5 Chat (4B)  Qwen 1.5 Chat (7B)  \\\n",
       "0                   3.0                 1.0                 6.0   \n",
       "1                   7.0                 0.0                 0.0   \n",
       "2                   5.0                 2.0                 5.0   \n",
       "3                   7.0                 1.0                 8.0   \n",
       "4                   7.0                 2.0                 2.0   \n",
       "\n",
       "   Qwen 1.5 Chat (14B)  Qwen 1.5 Chat (72B)  LLaMA-2 Chat (70B)  GPT-4o  \\\n",
       "0                  3.0                  3.0                 3.0     3.0   \n",
       "1                  3.0                  3.0                 6.0     5.0   \n",
       "2                  3.0                  4.0                 3.0     2.0   \n",
       "3                  6.0                  6.0                 8.0     8.0   \n",
       "4                  3.0                  4.0                 3.0     3.0   \n",
       "\n",
       "   GPT-3.5 Turbo  GPT-4 Turbo  GPT-4o W/O Reasoning  Sentiment Roberta  \\\n",
       "0            3.0          5.0                   2.0           3.000812   \n",
       "1            5.0          6.0                   1.0           5.122762   \n",
       "2            2.0          3.0                   3.0           4.173433   \n",
       "3            8.0          8.0                   8.0           6.907494   \n",
       "4            2.0          2.0                   2.0           4.960894   \n",
       "\n",
       "   Custmized Bert  \n",
       "0        3.385936  \n",
       "1        6.015794  \n",
       "2        4.166149  \n",
       "3        7.103713  \n",
       "4        3.268210  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = [i for i in range(1, 20)]\n",
    "data = pd.read_csv('all_data.csv', usecols = col_list)\n",
    "data.drop(columns = ['label'], inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885326e2",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "- Take most capable LLM model and compare it against conventional \n",
    "    - Ex. Gpt or Llama or Qwen against conventional \n",
    "    - Rank LLM's by the mean absolute error across the model data (`test_stats`)\n",
    "- Use two-sample hypothesis test\n",
    "- Data is shifted from the scoring to absolute difference (distance) from average human rating (`|model_score - average_human_score|`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bdb9d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Qwen 1.5 Chat (72B)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_ind = np.where(test_stats == min(test_stats[:-2]))[0][0]\n",
    "test_model = models[test_model_ind]\n",
    "test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362abb2e",
   "metadata": {},
   "source": [
    "We want to know if conventional models or LLMs perform better. Our data will be the absolute differences (AD) between model rating and human rating \n",
    "\n",
    "- $X \\sim N(\\mu_x, \\sigma_x ^2)$ and $Y \\sim N(\\mu_y, \\sigma_y ^2)$ are both the absolute difference between model X and model Y scoring and the average human score\n",
    "\n",
    "\n",
    "| Anatomy of the hypothesis test |  Answer  |\n",
    "|:------------------------------:|:--------:|\n",
    "| Assumption                     | $$X \\sim N(\\mu_x, \\sigma_x ^2)$$ and $$Y \\sim N(\\mu_y, \\sigma_y ^2)$$ |\n",
    "| Population parameter           | $$\\theta = \\mu_x - \\mu_y$$ |\n",
    "| Sample statistic               | $$\\hat\\theta = \\overline{X} - \\overline{Y}$$ |\n",
    "| Test statistic                 | $$T = \\displaystyle\\frac{\\hat\\theta - \\theta}{\\text{SE}} \\sim t_{k}$$ |\n",
    "| Null hypothesis                | $$H_0: \\theta = 0$$ |\n",
    "| Alternate hypothesis           | $$H_a: \\theta > 0$$ |\n",
    "| Rejection region shape         | $$(x_\\alpha, \\infty)$$ |\n",
    "\n",
    "- We will use $\\alpha = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93439b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicole/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "best_llm = abs(data[test_model] - data['average'])\n",
    "roberta = abs(data['Sentiment Roberta'] - data['average'])\n",
    "bert = abs(data['Custmized Bert'] - data['average'])\n",
    "\n",
    "berta_stat, berta_p = stats.ttest_ind(best_llm, roberta, alternative = 'greater')\n",
    "\n",
    "# 'greater’: the mean of the distribution underlying the first sample is greater than the \n",
    "# mean of the distribution underlying the second sample; the llm absolute difference is greater than the\n",
    "# roberta absolute difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5424669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_stat, bert_p = stats.ttest_ind(best_llm, bert, alternative = 'greater')\n",
    "\n",
    "# 'greater’: the mean of the distribution underlying the first sample is greater than the \n",
    "# mean of the distribution underlying the second sample; the llm absolute difference is greater than the\n",
    "# bert absolute difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1ae2658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.05, p_value = 2.6596145689960566e-11\n",
      "Reject null: LLMs have a larger mean -> LLMs have a larger error and a worse performance \n"
     ]
    }
   ],
   "source": [
    "def decide(alpha, p_value):\n",
    "    if p_value < alpha:\n",
    "        print(f'alpha = {alpha}, p_value = {p_value}')\n",
    "        print('Reject null: LLMs have a larger mean -> LLMs have a larger error and a worse performance ')\n",
    "    else:\n",
    "        print(f'alpha = {alpha}, p_value = {p_value}')\n",
    "        print('Fail to reject null: LLMs do not appear have a larger mean -> LLMs and conventional models have similar perfomances')\n",
    "    \n",
    "alpha = 0.05\n",
    "decide(alpha, berta_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea224fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qwen 1.5 Chat (0.5B)</th>\n",
       "      <th>Qwen 1.5 Chat (1.8B)</th>\n",
       "      <th>Qwen 1.5 Chat (4B)</th>\n",
       "      <th>Qwen 1.5 Chat (7B)</th>\n",
       "      <th>Qwen 1.5 Chat (14B)</th>\n",
       "      <th>Qwen 1.5 Chat (72B)</th>\n",
       "      <th>LLaMA-2 Chat (70B)</th>\n",
       "      <th>GPT-4o</th>\n",
       "      <th>GPT-3.5 Turbo</th>\n",
       "      <th>GPT-4 Turbo</th>\n",
       "      <th>GPT-4o W/O Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Qwen 1.5 Chat (0.5B)  Qwen 1.5 Chat (1.8B)  Qwen 1.5 Chat (4B)  \\\n",
       "0                     1.0                   3.0                 1.0   \n",
       "1                     7.0                   7.0                 0.0   \n",
       "2                     7.0                   5.0                 2.0   \n",
       "3                     7.0                   7.0                 1.0   \n",
       "4                     7.0                   7.0                 2.0   \n",
       "..                    ...                   ...                 ...   \n",
       "245                   0.0                   5.0                 6.0   \n",
       "246                   7.0                   7.0                 1.0   \n",
       "247                   5.0                   1.0                 6.0   \n",
       "248                   9.0                  10.0                 0.0   \n",
       "249                   7.0                   7.0                10.0   \n",
       "\n",
       "     Qwen 1.5 Chat (7B)  Qwen 1.5 Chat (14B)  Qwen 1.5 Chat (72B)  \\\n",
       "0                   6.0                  3.0                  3.0   \n",
       "1                   0.0                  3.0                  3.0   \n",
       "2                   5.0                  3.0                  4.0   \n",
       "3                   8.0                  6.0                  6.0   \n",
       "4                   2.0                  3.0                  4.0   \n",
       "..                  ...                  ...                  ...   \n",
       "245                 1.0                  3.0                  5.0   \n",
       "246                 7.0                  6.0                  8.0   \n",
       "247                 6.0                  4.0                  5.0   \n",
       "248                 9.0                  7.0                  5.0   \n",
       "249                 9.0                  6.0                  8.0   \n",
       "\n",
       "     LLaMA-2 Chat (70B)  GPT-4o  GPT-3.5 Turbo  GPT-4 Turbo  \\\n",
       "0                   3.0     3.0            3.0          5.0   \n",
       "1                   6.0     5.0            5.0          6.0   \n",
       "2                   3.0     2.0            2.0          3.0   \n",
       "3                   8.0     8.0            8.0          8.0   \n",
       "4                   3.0     3.0            2.0          2.0   \n",
       "..                  ...     ...            ...          ...   \n",
       "245                 3.0     3.0            2.0          4.0   \n",
       "246                 8.0     8.0            8.0          8.0   \n",
       "247                 3.0     3.0            3.0          3.0   \n",
       "248                 8.0     8.0            9.0          8.0   \n",
       "249                 8.0     6.0            6.0          8.0   \n",
       "\n",
       "     GPT-4o W/O Reasoning  \n",
       "0                     2.0  \n",
       "1                     1.0  \n",
       "2                     3.0  \n",
       "3                     8.0  \n",
       "4                     2.0  \n",
       "..                    ...  \n",
       "245                   1.0  \n",
       "246                   8.0  \n",
       "247                   2.0  \n",
       "248                   8.0  \n",
       "249                   5.0  \n",
       "\n",
       "[250 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = data.iloc[:, 5:-2]\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10a291b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen 1.5 Chat (72B)     1.058667\n",
       "GPT-4 Turbo             1.240000\n",
       "Qwen 1.5 Chat (14B)     1.280000\n",
       "LLaMA-2 Chat (70B)      1.369333\n",
       "GPT-4o                  1.442667\n",
       "GPT-3.5 Turbo           1.569333\n",
       "GPT-4o W/O Reasoning    1.626667\n",
       "Qwen 1.5 Chat (7B)      2.006667\n",
       "Qwen 1.5 Chat (1.8B)    2.688000\n",
       "Qwen 1.5 Chat (4B)      3.160000\n",
       "Qwen 1.5 Chat (0.5B)    3.568000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in llm_response.columns:\n",
    "    llm_response[col] = abs(llm_response[col] - data['average'])\n",
    "perf = llm_response.mean(axis = 0).sort_values(ascending = True)\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30862cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Qwen 1.5 Chat (72B)',\n",
       " 'GPT-4 Turbo',\n",
       " 'Qwen 1.5 Chat (14B)',\n",
       " 'LLaMA-2 Chat (70B)',\n",
       " 'GPT-4o',\n",
       " 'GPT-3.5 Turbo',\n",
       " 'GPT-4o W/O Reasoning',\n",
       " 'Qwen 1.5 Chat (7B)',\n",
       " 'Qwen 1.5 Chat (1.8B)',\n",
       " 'Qwen 1.5 Chat (4B)',\n",
       " 'Qwen 1.5 Chat (0.5B)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(perf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a64895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "def decide_LLM(alpha, p_value):\n",
    "    if p_value < alpha:\n",
    "        print(f'alpha = {alpha}, p_value = {p_value}')\n",
    "        print('Reject null: Model 1 is significantly better than Model 2')\n",
    "    else:\n",
    "        print(f'alpha = {alpha}, p_value = {p_value}')\n",
    "        print('Fail to reject null: Model 1 is not significantly better than Model 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35271b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.05, p_value = 0.010857275426296862\n",
      "Reject null: Model 1 is significantly better than Model 2\n"
     ]
    }
   ],
   "source": [
    "# Qwen 1.5 Chat (72B) vs GPT-4 Turbo (between different LLMs)\n",
    "stat1, p_value1 = stats.ttest_ind(llm_response['Qwen 1.5 Chat (72B)'], llm_response['GPT-4 Turbo'], alternative = 'less')\n",
    "decide_LLM(alpha, p_value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a5fd7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.05, p_value = 0.06650384176944449\n",
      "Fail to reject null: Model 1 is not significantly better than Model 2\n"
     ]
    }
   ],
   "source": [
    "# GPT-4 Turbo vs LLaMA-2 Chat (70B) (between different LLMs)\n",
    "stat2, p_value2 = stats.ttest_ind(llm_response['GPT-4 Turbo'], llm_response['LLaMA-2 Chat (70B)'], alternative = 'less')\n",
    "decide_LLM(alpha, p_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "450a446f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.05, p_value = 0.007313356292272543\n",
      "Reject null: Model 1 is significantly better than Model 2\n"
     ]
    }
   ],
   "source": [
    "# GPT-4 Turbo vs GPT-4o (GPT4o is the newest model, but GPT-4 Turbo shows better performance in the test set. Is that significant?)\n",
    "stat2, p_value2 = stats.ttest_ind(llm_response['GPT-4 Turbo'], llm_response['GPT-4o'], alternative = 'less')\n",
    "decide_LLM(alpha, p_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "187b8d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.05, p_value = 0.005031223723426022\n",
      "Reject null: Model 1 is significantly better than Model 2\n"
     ]
    }
   ],
   "source": [
    "# Is Qwen 1.5 Chat (72B) significantly better than its smaller variant Qwen 1.5 Chat (14B)?\n",
    "stat2, p_value2 = stats.ttest_ind(llm_response['Qwen 1.5 Chat (72B)'], llm_response['Qwen 1.5 Chat (14B)'], alternative = 'less')\n",
    "decide_LLM(alpha, p_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc334650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
