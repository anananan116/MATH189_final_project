{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 5672, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,\n",
       "          102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Replace Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "val_data = pd.read_csv(\"data/cleaned_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.553870353677839"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(val_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zihan liu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def do_sentiment_analysis(df):\n",
    "    df = df.copy()\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    from transformers import AutoTokenizer, AutoConfig\n",
    "    import numpy as np\n",
    "    from scipy.special import softmax\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from tqdm import tqdm\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    config = AutoConfig.from_pretrained(MODEL)\n",
    "    scores_all = []\n",
    "    labels_all = []\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "    dataloader = DataLoader(df['text'], batch_size = 512)\n",
    "    for batch in tqdm(dataloader):\n",
    "        encoded_input = tokenizer(batch, return_tensors='pt', padding = True, truncation = True, max_length = 100)\n",
    "        encoded_input.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "        scores = F.softmax(output.logits, dim=-1)\n",
    "        labels = torch.argmax(scores, dim = -1).cpu().numpy()\n",
    "        scores = scores.cpu().numpy()\n",
    "        scores_all.extend(scores)\n",
    "        labels_all.extend(labels)\n",
    "    scores_all = np.array(scores_all)\n",
    "    labels_all = np.array(labels_all)\n",
    "    df['Negative_score'] = scores_all[:, 0]\n",
    "    df['Neutral_score'] = scores_all[:, 1]\n",
    "    df['Positive_score'] = scores_all[:, 2]\n",
    "    df['sentiment_labels'] = labels_all\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"data/cleaned_test.csv\")\n",
    "df = do_sentiment_analysis(df)\n",
    "def map_to_discrete_labels(label):\n",
    "    if label == 0.0:\n",
    "        return 0\n",
    "    elif label == 5.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "df['label'] = df['label'].apply(map_to_discrete_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "with open(\"./results/exp_main/results.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "softmax = torch.nn.Softmax(dim = 1)\n",
    "results = np.array(results)\n",
    "results = softmax(torch.tensor(results)).numpy()\n",
    "result_conventional = results[:, 0] * 2.5 + results[:, 1] * 5 + results[:, 2] * 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>Label_by_zihan</th>\n",
       "      <th>Label_by_ben</th>\n",
       "      <th>Label_by_nicole</th>\n",
       "      <th>average</th>\n",
       "      <th>label</th>\n",
       "      <th>Qwen 1.5 Chat (0.5B)</th>\n",
       "      <th>Qwen 1.5 Chat (1.8B)</th>\n",
       "      <th>Qwen 1.5 Chat (4B)</th>\n",
       "      <th>Qwen 1.5 Chat (7B)</th>\n",
       "      <th>Qwen 1.5 Chat (14B)</th>\n",
       "      <th>Qwen 1.5 Chat (72B)</th>\n",
       "      <th>LLaMA-2 Chat (70B)</th>\n",
       "      <th>GPT-4o</th>\n",
       "      <th>GPT-3.5 Turbo</th>\n",
       "      <th>GPT-4 Turbo</th>\n",
       "      <th>GPT-4o W/O Reasoning</th>\n",
       "      <th>Sentiment Roberta</th>\n",
       "      <th>Custmized Bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what do these '1/2 naked pics' have to do with...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000812</td>\n",
       "      <td>3.385936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.122762</td>\n",
       "      <td>6.015794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>That's coming, but I think the victims are goi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.173433</td>\n",
       "      <td>4.166149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.907494</td>\n",
       "      <td>7.103714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Wow,first Hugo Chavez and now Fidel Castro. Da...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.960894</td>\n",
       "      <td>3.268209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>245</td>\n",
       "      <td>Fake news, Election Day hacks, Wikileaks, Come...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.845540</td>\n",
       "      <td>3.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>246</td>\n",
       "      <td>I just want to move to LA, work a minimum wage...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.528737</td>\n",
       "      <td>5.824569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>I dunno, from my porch view of Europe, there i...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.557053</td>\n",
       "      <td>3.761463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>Watch Tesla Model S P85D’s instant speed avoid...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.371862</td>\n",
       "      <td>6.359703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>Positive news - #France to enforce labeling of...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.384174</td>\n",
       "      <td>6.414460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               text  \\\n",
       "0             0  what do these '1/2 naked pics' have to do with...   \n",
       "1             1  OH: “I had a blue penis while I was this” [pla...   \n",
       "2             2  That's coming, but I think the victims are goi...   \n",
       "3             3  I think I may be finally in with the in crowd ...   \n",
       "4             4  Wow,first Hugo Chavez and now Fidel Castro. Da...   \n",
       "..          ...                                                ...   \n",
       "245         245  Fake news, Election Day hacks, Wikileaks, Come...   \n",
       "246         246  I just want to move to LA, work a minimum wage...   \n",
       "247         247  I dunno, from my porch view of Europe, there i...   \n",
       "248         248  Watch Tesla Model S P85D’s instant speed avoid...   \n",
       "249         249  Positive news - #France to enforce labeling of...   \n",
       "\n",
       "     Label_by_zihan  Label_by_ben  Label_by_nicole   average  label  \\\n",
       "0               3.0           3.0              4.0  3.333333      5   \n",
       "1               5.0           5.0              6.0  5.333333      5   \n",
       "2               5.0           6.0              5.0  5.333333      5   \n",
       "3               7.0           9.0              7.0  7.666667     10   \n",
       "4               4.0           2.0              3.0  3.000000      0   \n",
       "..              ...           ...              ...       ...    ...   \n",
       "245             2.0           4.0              4.0  3.333333      0   \n",
       "246             5.0           6.0              6.0  5.666667      5   \n",
       "247             4.0           5.0              4.0  4.333333      0   \n",
       "248             7.0           6.0              7.0  6.666667     10   \n",
       "249             8.0           8.0              7.0  7.666667     10   \n",
       "\n",
       "     Qwen 1.5 Chat (0.5B)  Qwen 1.5 Chat (1.8B)  Qwen 1.5 Chat (4B)  \\\n",
       "0                     1.0                   3.0                 1.0   \n",
       "1                     7.0                   7.0                 0.0   \n",
       "2                     7.0                   5.0                 2.0   \n",
       "3                     7.0                   7.0                 1.0   \n",
       "4                     7.0                   7.0                 2.0   \n",
       "..                    ...                   ...                 ...   \n",
       "245                   0.0                   5.0                 6.0   \n",
       "246                   7.0                   7.0                 1.0   \n",
       "247                   5.0                   1.0                 6.0   \n",
       "248                   9.0                  10.0                 0.0   \n",
       "249                   7.0                   7.0                10.0   \n",
       "\n",
       "     Qwen 1.5 Chat (7B)  Qwen 1.5 Chat (14B)  Qwen 1.5 Chat (72B)  \\\n",
       "0                   6.0                  3.0                  3.0   \n",
       "1                   0.0                  3.0                  3.0   \n",
       "2                   5.0                  3.0                  4.0   \n",
       "3                   8.0                  6.0                  6.0   \n",
       "4                   2.0                  3.0                  4.0   \n",
       "..                  ...                  ...                  ...   \n",
       "245                 1.0                  3.0                  5.0   \n",
       "246                 7.0                  6.0                  8.0   \n",
       "247                 6.0                  4.0                  5.0   \n",
       "248                 9.0                  7.0                  5.0   \n",
       "249                 9.0                  6.0                  8.0   \n",
       "\n",
       "     LLaMA-2 Chat (70B)  GPT-4o  GPT-3.5 Turbo  GPT-4 Turbo  \\\n",
       "0                   3.0     3.0            3.0          5.0   \n",
       "1                   6.0     5.0            5.0          6.0   \n",
       "2                   3.0     2.0            2.0          3.0   \n",
       "3                   8.0     8.0            8.0          8.0   \n",
       "4                   3.0     3.0            2.0          2.0   \n",
       "..                  ...     ...            ...          ...   \n",
       "245                 3.0     3.0            2.0          4.0   \n",
       "246                 8.0     8.0            8.0          8.0   \n",
       "247                 3.0     3.0            3.0          3.0   \n",
       "248                 8.0     8.0            9.0          8.0   \n",
       "249                 8.0     6.0            6.0          8.0   \n",
       "\n",
       "     GPT-4o W/O Reasoning  Sentiment Roberta  Custmized Bert  \n",
       "0                     2.0           3.000812        3.385936  \n",
       "1                     1.0           5.122762        6.015794  \n",
       "2                     3.0           4.173433        4.166149  \n",
       "3                     8.0           6.907494        7.103714  \n",
       "4                     2.0           4.960894        3.268209  \n",
       "..                    ...                ...             ...  \n",
       "245                   1.0           2.845540        3.000003  \n",
       "246                   8.0           5.528737        5.824569  \n",
       "247                   2.0           3.557053        3.761463  \n",
       "248                   8.0           5.371862        6.359703  \n",
       "249                   5.0           6.384174        6.414460  \n",
       "\n",
       "[250 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"all_data.csv\")\n",
    "all_data['Sentiment Roberta'] = df['Negative_score'] * 2.5 + df['Neutral_score'] * 5 + df['Positive_score'] * 7.5\n",
    "all_data['Custmized Bert'] = result_conventional\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Qwen 1.5 Chat (0.5B)': 3.5679999999880003,\n",
       " 'Qwen 1.5 Chat (1.8B)': 2.687999999988,\n",
       " 'Qwen 1.5 Chat (4B)': 3.1599999999960002,\n",
       " 'Qwen 1.5 Chat (7B)': 2.006666666652,\n",
       " 'Qwen 1.5 Chat (14B)': 1.280000000004,\n",
       " 'Qwen 1.5 Chat (72B)': 1.0586666666359998,\n",
       " 'LLaMA-2 Chat (70B)': 1.369333333332,\n",
       " 'GPT-4o': 1.4426666666680001,\n",
       " 'GPT-3.5 Turbo': 1.5693333333400001,\n",
       " 'GPT-4 Turbo': 1.239999999996,\n",
       " 'GPT-4o W/O Reasoning': 1.6266666666679999,\n",
       " 'Sentiment Roberta': 0.6257107210039301,\n",
       " 'Custmized Bert': 0.8029645176133838}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_results = {}\n",
    "model_columns = all_data.columns[7:]\n",
    "\n",
    "for model in model_columns:\n",
    "    mae = (all_data[model] - all_data['average']).abs().mean()\n",
    "    mae_results[model] = mae\n",
    "\n",
    "mae_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"all_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
